{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Custom Search API\n",
    "\n",
    "## Part I: Getting URLs\n",
    "\n",
    "To use the API, we need to get an engine ID and API key from the [Google Custom Search API](https://developers.google.com/custom-search/v1/overview). The code presented here demonstrates querying keywords of recyclables and non-recyclables and storing data in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient.discovery import build\n",
    "import cnfg\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file (engine ID and api key registered from Google API)\n",
    "# config = {'api_key': 'XXXX', 'engine_ID': 'XXXX'}\n",
    "url = '/Users/lkchemposer/.googleapi_config'\n",
    "config = cnfg.load(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a collection\n",
    "service = build('customsearch', 'v1', developerKey=config['api_key'])\n",
    "collections = service.cse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords to query (from https://www1.nyc.gov/assets/dsny/site/services/recycling/what-to-recycle)\n",
    "metal = ['metal can', 'crushed metal can', 'pet food can', 'paint can', 'soup can', 'aluminum foil', 'aluminum tray',\n",
    "         'metal lid', 'metal wire hanger', 'metal pot', 'metal tool', 'metal curtain rod', 'license plate']\n",
    "glass = ['glass jar', 'glass soda bottles']\n",
    "plastic = ['plastic soda bottles', 'plastic water bottle', 'hard plastic water bottle', 'plastic milk jug',\n",
    "           'plastic jar', 'plastic lid', 'plastic tupperware', 'plastic food container', 'plastic cookie insert',\n",
    "           'plastic yogurt container', 'plastic dairy tub', 'plastic clamshell container',\n",
    "           'plastic blister pack container', 'acetate box', 'plastic flower pot', 'plastic mixing bowl',\n",
    "           'plastic crate', 'plastic bucket', 'plastic pail', 'plastic chair', 'plastic toy']\n",
    "paper = ['carton food box', 'carton box', 'milk carton packaging', 'beverage carton packaging', 'carton drink box',\n",
    "         'carton aseptic package', 'carton juice box', 'carton soup', 'newspaper', 'magazine', 'yellow pages',\n",
    "         'mixed paper', 'white scrunched paper', 'lined paper', 'crumpled paper', 'sheet music', 'envelope',\n",
    "         'paper receipt', 'paper bag', 'wrapping paper', 'paperback book', 'comic book', 'cardboard egg carton',\n",
    "         'cardboard tray', 'cardboard shoe box', 'cardboard tube', 'paper file folders', 'cardboard packaging',\n",
    "         'pizza box', 'cardboard sleeve', 'paper cup', 'corrugated cardboard']\n",
    "recs = metal + glass + plastic + paper\n",
    "\n",
    "\n",
    "nrplastic = ['candy wrapper', 'spiral binding', 'styrofoam container', 'styrofoam plate', 'styrofoam cup',\n",
    "             'styrofoam tray', 'foam packing peanut', 'flexible plastic tube', 'lotion', 'toothpaste tubes',\n",
    "             'cosmetics', 'basketball ball', 'bowling ball', 'soccer ball', 'american football ball', 'yoga ball',\n",
    "             'plastic shopping bag']\n",
    "nrglass = ['light bulb', 'mirror', 'glassware']\n",
    "tanglers = ['cable', 'wire', 'cord', 'hose']\n",
    "other = ['battery', 'printer cartridge', 'ceramic', 'cigarette lighter', 'gas lighter', 'cassette', 'VHS tape',\n",
    "         'pen', 'marker']\n",
    "\n",
    "nonrecs = nrplastic + nrglass + tanglers + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query recyclables keywords to get URLs, image type, and caption\n",
    "l = list()\n",
    "for query in recs:\n",
    "    for i in list(range(1, 100, 10)): # maximum 100 results\n",
    "        try:\n",
    "            request = collections.list(q=query, start=i, filter='1', # no duplicate results\n",
    "                                       searchType='image', imgType='photo', imgColorType='color',\n",
    "                                       cx=config['engine_ID'])\n",
    "            time.sleep(1)\n",
    "            response = request.execute()\n",
    "            for image in response['items']:\n",
    "                link = image['link']\n",
    "                typ = image['mime']\n",
    "                capt = image['title'].lower()\n",
    "                l.append(dict(zip(['class', 'link', 'type', 'caption'], [query, link, typ, capt])))\n",
    "                if i == 91: # store results in csv\n",
    "                    images = pd.DataFrame(l)\n",
    "                    images.to_csv('Recs.csv', mode='a', index=False, header=None)\n",
    "                    l = list() # reset list and dataframe\n",
    "                    images = pd.DataFrame()\n",
    "            if i == 1: # checking progress at the start of each keyword\n",
    "                display.clear_output()\n",
    "                print(query)       \n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for non-recyclables\n",
    "l = list()\n",
    "for query in nonrecs:\n",
    "    for i in list(range(1, 100, 10)): # maximum 100 results\n",
    "        try:\n",
    "            request = collections.list(q=query, start=i, filter='1', # no duplicate results\n",
    "                                       searchType='image', imgType='photo', imgColorType='color',\n",
    "                                       cx=config['engine_ID'])\n",
    "            time.sleep(1)\n",
    "            response = request.execute()\n",
    "            for image in response['items']:\n",
    "                link = image['link']\n",
    "                typ = image['mime']\n",
    "                capt = image['title'].lower()\n",
    "                l.append(dict(zip(['class', 'link', 'type', 'caption'], [query, link, typ, capt])))\n",
    "                if i == 91: # store results in csv\n",
    "                    images = pd.DataFrame(l)\n",
    "                    images.to_csv('Nonrecs.csv', mode='a', index=False, header=None)\n",
    "                    l = list() # reset list and dataframe\n",
    "                    images = pd.DataFrame()\n",
    "            if i == 1: # checking progress at the start of each keyword\n",
    "                display.clear_output()\n",
    "                print(query)       \n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Image Downloading and Cleaning\n",
    "\n",
    "Here, we:\n",
    "1. Remove duplicate links and captions\n",
    "2. Organize classes of material in the CSV files\n",
    "3. Download images and store them in appropriately named folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting duplicate links and caption (same images sometimes have distinct links but same caption)\n",
    "rdf = pd.read_csv('Recs.csv', names=sorted(['class', 'link', 'type', 'caption']))\n",
    "rdf.drop_duplicates('link', inplace=True)\n",
    "rdf.drop_duplicates('caption', inplace=True)\n",
    "\n",
    "nrdf = pd.read_csv('Nonrecs.csv', names=sorted(['class', 'link', 'type', 'caption']))\n",
    "nrdf.drop_duplicates('link', inplace=True)\n",
    "nrdf.drop_duplicates('caption', inplace=True)\n",
    "\n",
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify items into materials\n",
    "recsd = {'metal': metal, 'glass': glass, 'plastic': plastic, 'paper': paper}\n",
    "nrecsd = {'glass': nrglass, 'plastic': nrplastic, 'tanglers': tanglers, 'other': other}\n",
    "\n",
    "def rclassify(row):\n",
    "    for key in recsd:\n",
    "        if row['class'] in recsd[key]:\n",
    "            return str(key)\n",
    "\n",
    "rdf['class'] = rdf.apply(rclassify, axis=1)\n",
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrclassify(row):\n",
    "    for key in nrecsd:\n",
    "        if row['class'] in nrecsd[key]:\n",
    "            return str(key)\n",
    "\n",
    "nrdf['class'] = nrdf.apply(nrclassify, axis=1)\n",
    "nrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for image files\n",
    "import os\n",
    "import sys\n",
    "from urllib.request import urlretrieve as download\n",
    "\n",
    "drs = ['recs_glass', 'recs_metal', 'recs_paper', 'recs_plastic',\n",
    "       'nonrecs_glass', 'nonrecs_other', 'nonrecs_tanglers', 'nonrecs_plastic']\n",
    "\n",
    "for i in drs:\n",
    "    os.mkdir(os.path.join('./data/', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading images from urls\n",
    "t = 0\n",
    "for i in rdf.index:\n",
    "    if t == 100:\n",
    "        break\n",
    "    try:\n",
    "        download(rdf['link'][i], './data/{}_{}/{}-{}.jpg'.format('recs', rdf['class'][i],\n",
    "                                                                  rdf['class'][i], i))\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        continue\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Deleting Errorneous Image Files\n",
    "\n",
    "Lastly, some image files cannot be opened by PIL, so we remove them to prevent errors from occurring in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for j in drs:\n",
    "    for i in os.listdir(os.path.join('./data/', j)):\n",
    "        p = os.path.join('./data/', j, i)\n",
    "        try:\n",
    "            Image.open(p)\n",
    "        except:\n",
    "            os.remove(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
